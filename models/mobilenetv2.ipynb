{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mobilenetv2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpH7NoEpcTOS"
      },
      "source": [
        "### Cách đọc file thông thường và tf.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey81xHuz3OaG"
      },
      "source": [
        "#### ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOfg9E6BcOir",
        "outputId": "35e7ce53-2743-4cb5-a437-1651e41b7a20"
      },
      "source": [
        "%cd \"/content/drive/MyDrive/grocery-images\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1gVocdgOjp7dnVo8rM6lz1Io7VjaCD6nR/grocery-images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN5SKCoQBLtD"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.data import AUTOTUNE\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications import mobilenet_v2\n",
        "from tensorflow.keras import models, layers\n",
        "from imutils import paths\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9JtFUqhaVgW"
      },
      "source": [
        "def benchmark(datasetGen, numSteps):\n",
        "  start = time.time()\n",
        "  \n",
        "  for i in range(0, numSteps):\n",
        "    images, labels = next(datasetGen)\n",
        "\n",
        "  end = time.time()\n",
        "  return end - start"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyAufR76bVMH"
      },
      "source": [
        "cur_dir = os.getcwd()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od26dh0xOTcr"
      },
      "source": [
        "numSteps = 1\n",
        "BS = 64"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PNVNDPUauuk",
        "outputId": "dabab254-dbc1-46b7-aa9a-ab7c46c396f1"
      },
      "source": [
        "imageGen = ImageDataGenerator(rescale=1/.255, \n",
        "                              preprocessing_function=mobilenet_v2.preprocess_input)\n",
        "dataGen = imageGen.flow_from_directory(\n",
        "    cur_dir,\n",
        "    target_size=(224, 224),\n",
        "    class_mode='categorical',\n",
        "    batch_size=BS\n",
        ")"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 623 images belonging to 66 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt4Fgruob7vM"
      },
      "source": [
        "numSteps = 1\n",
        "BS = 64"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcvAAiTubhwq",
        "outputId": "30951330-6994-4980-dd6c-0a87d47c68ab"
      },
      "source": [
        "totalTime = benchmark(dataGen, numSteps)\n",
        "print(f'ImageDataGenerator generates {BS * numSteps} images in {totalTime}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "ImageDataGenerator generates 64 images in 83.21854591369629\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QonblmLPtGiz"
      },
      "source": [
        "Dữ liệu chỉ 623 ảnh và batch size khá lớn nhưng phải tốn 18s để load dữ liệu một lần -> không hiệu quả"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ijiX72cvxg8"
      },
      "source": [
        "#### tf.data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNsUBfNTvuvG"
      },
      "source": [
        "def load_images(imagePath, pretrained_net, required_size=(160, 160)):\n",
        "  image = tf.io.read_file(imagePath) # đọc file\n",
        "  image = tf.cast(tf.image.decode_png(image, channels=3), tf.float32) / 255.0 # chuyển về ảnh png\n",
        "  image = tf.image.resize(image, required_size) # kích thước đầu vào\n",
        "  image = pretrained_net.preprocess_input(image) # tiền xử lí theo pretrained model\n",
        "\n",
        "  label = tf.strings.split(imagePath, os.path.sep)[-2] # lấy tên nhãn\n",
        "  oneHot = tf.cast(label == classNames, tf.int32) # thực hiện one-hot encoding\n",
        "  encodedLabel = tf.argmax(oneHot) # lấy giá trị lớn nhất - vị trí của nhãn\n",
        "  return image, encodedLabel"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnOJo7mFzCxx"
      },
      "source": [
        "imagePath = list(paths.list_images(cur_dir))\n",
        "classNames = sorted(os.listdir(cur_dir))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD_0hlJgwdo8"
      },
      "source": [
        "def create_dataset(BS, pretrained_net):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(imagePath)\n",
        "  dataset = (dataset\n",
        "            .shuffle(1024) # (1)\n",
        "            .map(lambda x: load_images(x, pretrained_net), num_parallel_calls=AUTOTUNE) # (2)\n",
        "            .cache() # (3)\n",
        "            .repeat() # (4)\n",
        "            .batch(BS) # (5)\n",
        "            .prefetch(AUTOTUNE) # (6) \n",
        "            )\n",
        "  return dataset"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myBdapvs47qR"
      },
      "source": [
        "(1): khởi tạo một buffer có kích thước truyền vào, mỗi step lấy ra từ buffer số lượng dữ liệu tương ứng 1 batch size và lấy dữ liệu từ tập nguồn để làm đầy lại\n",
        "\n",
        "(2): vì dữ liệu truyền vào là một danh sách các đường dẫn ảnh => hàm map ánh xạ từng phần tử và thực hiện phép biến đổi tương ứng\n",
        "\n",
        "(3): caching để ghi nhớ lại dữ liệu đã sử dụng, tăng tốc độ tính toán\n",
        "\n",
        "(4): Khi lấy hết dữ liệu từ tập nguồn thì cần làm đầy lại\n",
        "\n",
        "(5): số lượng ảnh mỗi batch\n",
        "\n",
        "(6): thực hiện song song việc chuẩn bị dữ liệu trước đó và tính toán dữ liệu hiện tại"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwNUH-H3x1Cy",
        "outputId": "2a3bd03d-266d-44a6-dfeb-623ba476f937"
      },
      "source": [
        "dataset = create_dataset(BS, mobilenet_v2)\n",
        "totalTime = benchmark(iter(dataset), numSteps)\n",
        "print(f'tf.data API generates {BS * numSteps} in {totalTime}')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "tf.data API generates 64 in 44.91099834442139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWecundk1__q"
      },
      "source": [
        "tf.data API nhanh hơn gấp 2 lần ImageDataGenerator cho mỗi bước(dữ liệu trong 1 batch), con số này càng dao động đáng kể khi dữ liệu càng lớn\n",
        "\n",
        "=> Sử dụng tf.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHl13cWy8BAr"
      },
      "source": [
        "### Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok7JOE2SyBe9"
      },
      "source": [
        "mobilenet = MobileNetV2(include_top=False, weights='imagenet', input_shape=(160, 160, 3), pooling='avg')"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqWnjJqRRM1c"
      },
      "source": [
        "thông thường batch size lớn sẽ lợi về thời gian tuy nhiên sẽ mất đi chút chính xác\n",
        "\n",
        "dữ liệu tương đối ít nên sử dụng batch size nhỏ\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atsRiTRqQ5lN"
      },
      "source": [
        "BS = 16\n",
        "epochs = 15\n",
        "num_images = 623\n",
        "steps_per_epoch = num_images // BS"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d-R0ED1Q0vU"
      },
      "source": [
        "dataset = create_dataset(BS, mobilenet_v2)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg1G3BrDyFo4"
      },
      "source": [
        "mobilenet.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    mobilenet,\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(classNames.__len__(), activation='softmax')\n",
        "]\n",
        ")\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "NuXdg5gUQfI3",
        "outputId": "787eda8c-18e5-40af-db31-3121f56328c3"
      },
      "source": [
        "history = model.fit(dataset, epochs=epochs, steps_per_epoch=steps_per_epoch)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "38/38 [==============================] - 87s 2s/step - loss: 4.2287 - acc: 0.0115\n",
            "Epoch 2/15\n",
            "38/38 [==============================] - 3s 31ms/step - loss: 4.1925 - acc: 0.0115\n",
            "Epoch 3/15\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 4.1886 - acc: 0.0247\n",
            "Epoch 4/15\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 4.1878 - acc: 0.0230\n",
            "Epoch 5/15\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 4.1866 - acc: 0.0247\n",
            "Epoch 6/15\n",
            "38/38 [==============================] - 1s 29ms/step - loss: 4.1850 - acc: 0.0247\n",
            "Epoch 7/15\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 4.1843 - acc: 0.0230\n",
            "Epoch 8/15\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 4.1830 - acc: 0.0247\n",
            "Epoch 9/15\n",
            "13/38 [=========>....................] - ETA: 0s - loss: 4.1892 - acc: 0.0144"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-146-5320838a8ce1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm46b7wiRbLH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}